{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1916756b",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 3: Detectando atributos de personas.\n",
    "\n",
    "## Integrantes: Cravero, Ulises y Pautasso, L. Nicolás.\n",
    "## Tema: CS:GO Professional Matches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0201c3",
   "metadata": {},
   "source": [
    "### Imports y configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "799902fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# un poco menos de warnings de tensorflow\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# de python, para especificar rutas de archivos y directorios\n",
    "from pathlib import Path\n",
    "\n",
    "# lib para trabajar con arrays\n",
    "import numpy as np\n",
    "\n",
    "# lib que usamos para mostrar las imágenes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# libs que usamos para construir y entrenar redes neuronales, y que además tiene utilidades para leer sets de imágenes\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# libs que usamos para tareas generales de machine learning. En este caso, métricas\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# configuración para que las imágenes se vean dentro del notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# para descargar los datasets desde kaggle\n",
    "import opendatasets as od\n",
    "\n",
    "# para dividir el dataset\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918bf1f5",
   "metadata": {},
   "source": [
    "### Descarga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22661674",
   "metadata": {},
   "source": [
    "#### Descargamos el dataset desde Kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "246f2b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading celeba-dataset.zip to ./celeba-dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1.33G/1.33G [01:42<00:00, 14.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# descargamos el dataset correspondiente desde Kaggle\n",
    "od.download(\"https://www.kaggle.com/datasets/jessicali9530/celeba-dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae284e5",
   "metadata": {},
   "source": [
    "#### Dividimos las imágenes en directorios dependiendo a que conjunto de datos pertenece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71e2e683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruta del directorio donde se descargaron las imágenes\n",
    "directory = \"./celeba-dataset/img_align_celeba/img_align_celeba\"\n",
    "\n",
    "# creamos las carpetas de destino\n",
    "output_directory = \"./partitions\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# leemos el archivo de las particiones de las imagenes\n",
    "list_partition = pd.read_csv(\"./celeba-dataset/list_eval_partition.csv\")\n",
    "\n",
    "# filtramos y movemos las imágenes a las carpetas correspondientes (0 = train, 1 = validation y 2 = test)\n",
    "for index, row in list_partition.iterrows():\n",
    "    image_id = row['image_id']\n",
    "    partition = row['partition']\n",
    "    source_path = os.path.join(directory, f\"{image_id}\")\n",
    "    destination_path = os.path.join(output_directory, str(partition), f\"{image_id}\")\n",
    "    os.makedirs(os.path.dirname(destination_path), exist_ok=True)\n",
    "    shutil.copyfile(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72524552",
   "metadata": {},
   "source": [
    "#### Instanciamos las variables que contienen cada conjunto de datos dependiendo el path que obtuvimos antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e5da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurar de acuerdo a dónde bajaron los sets de imágenes\n",
    "TRAIN_DIR = Path('./partition/0')\n",
    "VALIDATION_DIR = Path('./partition/1')\n",
    "TEST_DIR = Path('./partition/2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
